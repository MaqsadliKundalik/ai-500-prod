"""
Voice Assistant Endpoints
=========================
Speech-to-text, text-to-speech, NLU processing
"""

from typing import Optional
from fastapi import APIRouter, Depends, File, UploadFile, HTTPException, status
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
import io

from app.core.dependencies import get_db, get_current_active_user, get_optional_user_id
from app.schemas.voice import (
    VoiceQueryResponse,
    TextQueryRequest,
    TextQueryResponse,
    TTSRequest,
    SupportedLanguage
)
from app.services.ai.voice_assistant import VoiceAssistantService

router = APIRouter()


@router.post("/query", response_model=VoiceQueryResponse)
async def voice_query(
    audio: UploadFile = File(..., description="Audio file (wav, mp3, m4a)"),
    language: SupportedLanguage = SupportedLanguage.AUTO,
    user_id: Optional[str] = Depends(get_optional_user_id),
    db: AsyncSession = Depends(get_db)
):
    """
    üé§ Process voice query.
    
    1. Converts speech to text (Faster-Whisper)
    2. Understands intent (OpenAI GPT-3.5 / Rasa)
    3. Executes action
    4. Returns text + audio response
    
    Supported languages:
    - **uz**: O'zbek tili
    - **ru**: –†—É—Å—Å–∫–∏–π
    - **en**: English
    - **auto**: Auto-detect
    """
    # Validate file type
    allowed_types = ["audio/wav", "audio/mp3", "audio/mpeg", "audio/m4a", "audio/x-m4a"]
    if audio.content_type not in allowed_types:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Unsupported audio format. Use: wav, mp3, m4a"
        )
    
    audio_data = await audio.read()
    
    voice_service = VoiceAssistantService(db)
    result = await voice_service.process_voice_query(
        audio_data=audio_data,
        language=language,
        user_id=user_id
    )
    
    return result


@router.post("/text-query", response_model=TextQueryResponse)
async def text_query(
    request: TextQueryRequest,
    user_id: Optional[str] = Depends(get_optional_user_id),
    db: AsyncSession = Depends(get_db)
):
    """
    Process text query through NLU.
    
    - **text**: User's question/command
    - **language**: Language code (uz, ru, en)
    
    Example queries:
    - "–ú–µ—Ç—Ñ–æ—Ä–º–∏–Ω –¥–æ—Ä–∏—Å–∏–Ω–∏ “õ–∏–¥–∏—Ä–∏–± —Ç–æ–ø–∏–Ω–≥"
    - "–ö–∞–∫–∏–µ –ø–æ–±–æ—á–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã —É –∞—Å–ø–∏—Ä–∏–Ω–∞?"
    - "Find nearest pharmacy"
    """
    voice_service = VoiceAssistantService(db)
    result = await voice_service.process_text_query(
        text=request.text,
        language=request.language,
        user_id=user_id
    )
    
    return result


@router.post("/tts")
async def text_to_speech(
    request: TTSRequest
):
    """
    üîä Convert text to speech.
    
    - **text**: Text to convert
    - **language**: Language for TTS (uz, ru, en)
    - **speed**: Speech speed (0.5 - 2.0)
    
    Returns audio file (MP3).
    """
    voice_service = VoiceAssistantService(None)  # No DB needed for TTS
    
    audio_bytes = await voice_service.text_to_speech(
        text=request.text,
        language=request.language,
        speed=request.speed
    )
    
    return StreamingResponse(
        io.BytesIO(audio_bytes),
        media_type="audio/mpeg",
        headers={"Content-Disposition": "attachment; filename=response.mp3"}
    )


@router.get("/supported-languages")
async def get_supported_languages():
    """
    Get list of supported languages for voice assistant.
    """
    return {
        "languages": [
            {
                "code": "uz",
                "name": "O'zbek tili",
                "stt_supported": True,
                "tts_supported": True
            },
            {
                "code": "ru",
                "name": "–†—É—Å—Å–∫–∏–π",
                "stt_supported": True,
                "tts_supported": True
            },
            {
                "code": "en",
                "name": "English",
                "stt_supported": True,
                "tts_supported": True
            }
        ]
    }


@router.get("/intents")
async def get_supported_intents():
    """
    Get list of supported voice command intents.
    """
    return {
        "intents": [
            {
                "name": "scan_medication",
                "examples": [
                    "Dori skanerlash",
                    "–û—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ª–µ–∫–∞—Ä—Å—Ç–≤–æ",
                    "Scan this medication"
                ]
            },
            {
                "name": "find_pharmacy",
                "examples": [
                    "Eng yaqin apteka",
                    "–ù–∞–π—Ç–∏ –±–ª–∏–∂–∞–π—à—É—é –∞–ø—Ç–µ–∫—É",
                    "Find nearest pharmacy"
                ]
            },
            {
                "name": "check_interaction",
                "examples": [
                    "Bu dori boshqa doriylar bilan to'qnashadimi?",
                    "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ",
                    "Check drug interactions"
                ]
            },
            {
                "name": "medication_info",
                "examples": [
                    "Aspirin haqida ma'lumot",
                    "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞—Ä–∞—Ü–µ—Ç–∞–º–æ–ª–µ",
                    "Tell me about ibuprofen"
                ]
            },
            {
                "name": "set_reminder",
                "examples": [
                    "Eslatma qo'y",
                    "–ù–∞–ø–æ–º–Ω–∏ –ø—Ä–∏–Ω—è—Ç—å —Ç–∞–±–ª–µ—Ç–∫–∏",
                    "Set medication reminder"
                ]
            }
        ]
    }
